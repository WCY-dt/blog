---
layout: post
title:  "从内存深入理解C语言"
date:   2021-02-01 00:00:00 +0800
categories: toturial
tags: C 内存 计算机组成
comments: 1
mathjax: true
---

本文主要通过剖析计算机内存机制，从底层解释C语言的运行。

# 程序运行

## 寄存器与缓存

**程序是保存在硬盘中的，要载入内存才能运行，CPU也被设计为只能从内存中读取数据和指令。**

对于CPU来说，内存仅仅是一个存放指令和数据的地方，并不能在内存中完成计算功能，例如要计算 a = b + c，必须将 a、b、c 都读取到CPU内部才能进行加法运算。为了了解具体的运算过程，不妨先来看一下CPU的结构。

CPU是一个复杂的计算机部件，它内部又包含很多小零件，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/5bbc3060700e649fc05ad96dc8dc9fca.png)


运算单元是CPU的大脑，负责加减乘除、比较、位移等运算工作，每种运算都有对应的电路支持，速度很快。

**寄存器（Register）是CPU内部非常小、非常快速的存储部件，它的容量很有限，对于32位的CPU，每个寄存器一般能存储32位（4个字节）的数据，对于64位的CPU，每个寄存器一般能存储64位（8个字节）的数据。为了完成各种复杂的功能，现代CPU都内置了几十个甚至上百个的寄存器，嵌入式系统功能单一，寄存器数量较少。**

**我们经常听说多少位的CPU，指的就是寄存器的的位数**。现在个人电脑使用的CPU已经进入了64位时代，例如 Intel 的 Core i3、i5、i7 等。

寄存器在程序的执行过程中至关重要，不可或缺，它们可以用来完成数学运算、控制循环次数、控制程序的执行流程、标记CPU运行状态等。例如，EIP（Extern Instruction Pointer ）寄存器的值是下一条指令的地址，CPU执行完当前指令后，会根据 EIP 的值找到下一条指令，改变 EIP 的值，就会改变程序的执行流程；CR3 寄存器保存着当前进程页目录的物理地址，切换进程就会改变 CR3 的值；EBP、ESP 寄存器用来指向栈的底部和顶部，函数调用会改变 EBP 和 ESP 的值。

那么，在CPU内部为什么又要设置缓存呢？虽然内存的读取速度已经很快了，但是和CPU比起来，还是有很大差距的，不是一个数量级的，如果每次都从内存中读取数据，会严重拖慢CPU的运行速度，CPU经常处于等待状态，无事可做。在CPU内部设置一个缓存，可以将使用频繁的数据暂时读取到缓存，需要同一地址上的数据时，就不用大老远地再去访问内存，直接从缓存中读取即可。

大家在购买CPU时，也会经常关心缓存容量，例如 Intel Core i7 3770K 的三级缓存为 8MB，二级缓存为 256KB，一级缓存为 32KB。容量越大，CPU越强悍。

**缓存的容量是有限的，CPU只能从缓存中读取到部分数据，对于使用不是很频繁的数据，会绕过缓存，直接到内存中读取。**所以不是每次都能从缓存中得到数据，这就是缓存的命中率，能够从缓存中读取就命中，否则就没命中。关于缓存的命中率又是一门学问，哪些数据保留在缓存，哪些数据不保留，都有复杂的算法。

## CPU指令

**要想让CPU工作，必须借助特定的指令，例如 add 用于加法运算，sub 用于减法运算，cmp 用于比较两个数的大小，这称为CPU的指令集（Instruction Set）。**我们的C语言代码最终也会编译成一条一条的CPU指令。不同型号的CPU支持的指令集会有所差异，但绝大部分是相同的。

我们以C语言中的加法为例来演示CPU指令的使用。假设有下面的C语言代码：

```bash
int a = 0x14, b = 0xAE, c;
c = a + b;
```

在VS2010 Debug模式下生成的CPU指令为：

```
mov  ptr[a], 0x14
mov  ptr[b], 0xAE
mov  eax, ptr[a]
add  eax, ptr[b]
mov  ptr[c], eax
```

mov 和 add 都是CPU指令：
**（1）mov 用来将一个数值移动到一个存储位置。**这个数值可以是一个常数，也可以在内存或者寄存器上；这个存储位置可以是寄存器或者内存。

第一条指令中， ptr[a]表示变量 a 的地址， 0X14是一个数值， mov ptr[a], 0X14表示把数值 0X14 移动到 ptr[a] 指向的内存，也就是给变量 a 赋值。第二条指令与此类似。

第三条指令中， eax是寄存器的名字，该寄存器常用在加法运算中，用来保存某个加数或运算结果， mov eax, ptr[a]表示把变量 a 的值移动到寄存器 eax 中。

第五条指令表示把寄存器 eax 的值移动到变量 c 中，此时 exa 中的值为 a、b 相加的和。

**（2）add 用来将两个数值相加，这两个数值可以在寄存器或者内存中，add 会将相加的结果放在第一个数所在的位置。**第四条指令 add eax, ptr[b]表示把 eax 和 ptr[a] 中的数值相加，并把结果放在 eax 中。

总起来讲：第一二条指令给变量 a、b 赋值，第三四条指令完成加法运算，第五条指令将运算结果赋值给变量 c。

**实际上，上面的代码是汇编语言，不是CPU指令，汇编语言还要经过简单的转换才能成为CPU指令**；为了更加容易地说明问题，这些语句也没有严格遵守汇编的语法。

# 虚拟内存

在C语言中，指针变量的值就是一个内存地址， &运算符的作用也是取变量的内存地址，请看下面的代码：

```cpp
#include <stdio.h>
#include <stdlib.h>
int a = 1, b = 255;
int main()
{
	int *p_a = &a;
	printf("p_a = %#X, &b = %#X\n", p_a, &b);
	system("pause");
	return 0;
}
```

在 C-Free 5.0 下运行，结果为：

```
p_a = 0X402000, &b = 0X402004
```

代码中的 a、b 是全局变量，它们的内存地址在链接时就已经决定了，以后再也不能改变，该程序无论在何时运行，结果都是一样的。

那么问题来了，如果物理内存中的这两个地址被其他程序占用了怎么办，我们的程序岂不是无法运行了？

幸运的是，这些内存地址都是假的，不是真实的物理内存地址，而是虚拟地址。虚拟地址通过CPU的转换才能对应到物理地址，而且每次程序运行时，操作系统都会重新安排虚拟地址和物理地址的对应关系，哪一段物理内存空闲就使用哪一段。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/0fb3afbd09dff8e1d2e5fd6be0a06b23.png)

## 虚拟地址

虚拟地址的整个想法是这样的：**把程序给出的地址看做是一种虚拟地址（Virtual Address），然后通过某些映射的方法，将这个虚拟地址转换成实际的物理地址。**这样，只要我们能够妥善地控制这个虚拟地址到物理地址的映射过程，就可以保证程序每次运行时都可以使用相同的地址。

例如，上面代码中变量 a 的地址是 0X402000，第一次运行时它对应的物理内存地址可能是 0X12ED90AA，第二次运行时可能又对应 0XED90，而我们的程序不需要关心这些，这些繁杂的内存管理工作交给操作系统处理即可。

让我们回到程序的运行本质上来。用户程序在运行时不希望介入到这些复杂的内存管理过程中，作为普通的程序，它需要的是一个简单的执行环境，有自己的内存，有自己的CPU，好像整个程序占有整个计算机而不用关心其他的程序。

**除了在编程时可以使用固定的内存地址，给程序员带来方便外，使用虚拟地址还能够使不同程序的地址空间相互隔离，提高内存使用效率。**

### 使不同程序的地址空间相互隔离

如果所有程序都直接使用物理内存，那么程序所使用的地址空间不是相互隔离的。恶意程序可以很容易改写其他程序的内存数据，以达到破坏的目的；有些非恶意、但是有 Bug 的程序也可能会不小心修改其他程序的数据，导致其他程序崩溃。

这对于需要安全稳定的计算机环境的用户来说是不能容忍的，用户希望他在使用计算机的时候，其中一个任务失败了，至少不会影响其他任务。

使用了虚拟地址后，程序A和程序B虽然都可以访问同一个地址，但它们对应的物理地址是不同的，无论如何操作，都不会修改对方的内存。

### 提高内存使用效率

使用虚拟地址后，操作系统会更多地介入到内存管理工作中，这使得控制内存权限成为可能。例如，我们希望**保存数据的内存没有执行权限，保存代码的内存没有修改权限，操作系统占用的内存普通程序没有读取权限**等。

另外，当物理内存不足时，操作系统能够更加灵活地控制换入换出的粒度，磁盘 I/O 是非常耗时的工作，这能够从很大程度上提高程序性能。

## 中间层思想

在计算机中，为了让操作更加直观、易于理解、增强用户体验，开发者经常会使用一件法宝——**增加中间层，即使用一种间接的方式来屏蔽复杂的底层细节，只给用户提供简单的接口**。虚拟地址是使用中间层的一个典型例子。

实际上，计算机的整个发展过程就是不断引入新的中间层：

- 计算机的早期，程序都是直接运行在硬件之上，自己负责硬件的管理工作；程序员也使用二进制进行编程，需要处理各种边界条件和安全问题。
- 后来人们不能忍受了，于是开发出了操作系统，让它来管理各种硬件，同时发明了汇编语言，减轻程序员的负担。
- 随着软件规模的不断增大，使用汇编语言编程开始变得捉襟见肘，不仅学习成本高，开发效率也很低，于是C语言诞生了。C语言编译器先将C代码翻译为汇编代码，再由汇编器将汇编代码翻译成机器指令。
- 随着计算机的发展，硬件越来越强大，软件越来越复杂，人们又不满足于使用C语言了，于是 C++、Java、C#、PHP 等现代化的编程语言诞生了。

# 虚拟地址

所谓虚拟地址空间，就是程序可以使用的虚拟地址的有效范围。虚拟地址和物理地址（一般指内存）的映射关系由操作系统决定，相应地，虚拟地址空间的大小也由操作系统决定，但还会受到编译模式的影响。

## CPU的数据处理能力

CPU是计算机的核心，决定了计算机的数据处理能力和寻址能力，也即决定了计算机的性能。CPU一次（一个时钟内）能处理的数据的大小由寄存器的位数和数据总线的宽度（也即有多少根数据总线）决定，**我们通常所说的多少位的CPU，除了可以理解为寄存器的位数，也可以理解数据总线的宽度，通常情况下它们是相等的**。、

**数据总线位于主板之上，不在CPU中，也不由CPU决定，严格来讲，这里应该说CPU能够支持的数据总线的最大根数，也即能够支持的最大数据处理能力**，为了表达方便，本文使用“CPU的数据总线”这一说法。

数据总线和主频都是CPU的重要指标：**数据总线决定了CPU单次的数据处理能力，主频决定了CPU单位时间内的数据处理次数，它们的乘积就是CPU单位时间内的数据处理量**。

我们常常听说，CPU主频在计算机的发展过程中飞速提升，从最初的几十 KHz，到后来的几百 MHz，再到现在的 4GHz，终于因为硅晶体的物理特性很难再提升，只能向多核方向发展。在这个过程中，CPU的数据总线宽度也在成倍增长，从早期的8位、16位，到后来的32位，现在我们计算机大部分都在使用64位CPU。

需要注意的是，**数据总线和地址总线不是一回事，数据总线用于在CPU和内存之间传输数据，地址总线用于在内存上定位数据，它们之间没有必然的联系，宽度并不一定相等**。实际情况是，**地址总线的宽度往往随着数据总线的宽度而增长，以访问更大的内存**。

### 16位CPU

早期的CPU是16位的，一次能处理 16Bit（2个字节）的数据。这个时候计算机产业还处在早期，个人电脑也没有进入千家万户，也没有提出虚拟地址的概念，程序还是直接运行在物理内存上，操作系统对内存的管理非常简陋，程序员轻易就能编写一个恶意程序去修改其他程序的内存。

学过汇编的同学应该知道，典型的16位处理器是 Intel 8086，它的数据总线有16根，地址总线有20根，寻址能力为 2^20 = 1MB。

### 32位CPU

随着计算机产业的进步，出现了32位的CPU，一次能处理 32Bit（4个字节）的数据。这个时候就提出了虚拟地址的概念，并被应用到CPU和操作系统中，由它们共同完成虚拟地址和物理地址的映射，这使得程序编写更加容易，运行更加安全。

典型的32位处理器是 Intel 的 80386 和 Intel Pentium 4（奔腾4）：80386 的数据总线和地址总线宽度都是32位，寻址能力达4GB；Pentium 4的地址总线宽度是36位，理论寻址能力达64GB。

### 64位CPU

现代计算机都使用64位的CPU，它们一次能处理64Bit（8个字节）的数据。典型的64位处理器是 Intel 的 Core i3、i5、i7 等，它们的地址总线宽度为 40~50 位左右。64位CPU的出现使个人电脑再次发生了质的飞跃。

## 实际支持的物理内存

CPU支持的物理内存只是理论上的数据，实际应用中还会受到操作系统的限制，例如，Win7  64位家庭版最大仅支持8GB或16GB的物理内存，Win7 64位专业版或企业版能够支持到192GB的物理内存。

Windows Server 2003 数据中心版专为大型企业或国家机构而设计，可以处理海量数据，分为32位版和64位版，32位版最高支持512GB的物理内存，这显然超出了32位CPU的寻址能力，可以通过两次寻址来实现。

## 编译模式

为了兼容不同的平台，现代编译器大都提供两种编译模式：32位模式和64位模式。

### 32位编译模式

在32位模式下，一个指针或地址占用4个字节的内存，共有32位，理论上能够访问的虚拟内存空间大小为 2^32 = 0X100000000 Bytes，即4GB，有效虚拟地址范围是 0 ~ 0XFFFFFFFF。 

也就是说，对于32位的编译模式，不管实际物理内存有多大，程序能够访问的有效虚拟地址空间的范围就是0 ~ 0XFFFFFFFF，也即虚拟地址空间的大小是 4GB。换句话说，程序能够使用的最大内存为 4GB，跟物理内存没有关系。

如果程序需要的内存大于物理内存，或者内存中剩余的空间不足以容纳当前程序，那么操作系统会将内存中暂时用不到的一部分数据写入到磁盘，等需要的时候再读取回来。而我们的程序只管使用 4GB 的内存，不用关心硬件资源够不够。

如果物理内存大于 4GB，例如目前很多PC机都配备了8GB的内存，那么程序也无能为力，它只能够使用其中的 4GB。

### 64位编译模式

在64位编译模式下，一个指针或地址占用8个字节的内存，共有64位，理论上能够访问的虚拟内存空间大小为 2^64。这是一个很大的值，几乎是无限的，就目前的技术来讲，不但物理内存不可能达到这么大，CPU的寻址能力也没有这么大，实现64位长的虚拟地址只会增加系统的复杂度和地址转换的成本，带不来任何好处，所以 Windows 和 Linux 都对虚拟地址进行了限制，仅使用虚拟地址的低48位（6个字节），总的虚拟地址空间大小为 2^48 = 256TB。

需要注意的是：

- **32位的操作系统只能运行32位的程序（也即以32位模式编译的程序），64位操作系统可以同时运行32位的程序（为了向前兼容，保留已有的大量的32位应用程序）和64位的程序（也即以64位模式编译的程序）。**
- **64位的CPU运行64位的程序才能发挥它的最大性能，运行32位的程序会白白浪费一部分资源。**

目前计算机可以说已经进入了64位的时代，之所以还要提供32位编译模式，是为了兼容一些老的硬件平台和操作系统，或者某些场合下32位的环境已经足够，使用64位环境会增大成本，例如嵌入式系统、单片机、工控等。

**这里所说的32位环境是指：32位的CPU + 32位的操作系统 + 32位的程序。**

# 内存对齐

## 内存对齐

计算机内存是以字节（Byte）为单位划分的，理论上CPU可以访问任意编号的字节，但实际情况并非如此。

CPU 通过地址总线来访问内存，一次能处理几个字节的数据，就命令地址总线读取几个字节的数据。32 位的 CPU 一次可以处理4个字节的数据，那么每次就从内存读取4个字节的数据；少了浪费主频，多了没有用。64位的处理器也是这个道理，每次读取8个字节。

以32位的CPU为例，实际寻址的步长为4个字节，也就是**只对编号为 4 的倍数的内存寻址**，例如 0、4、8、12、1000 等，而不会对编号为 1、3、11、1001 的内存寻址。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/3c354fa24ea5b2a23b142d7a398b255b.png)



这样做可以以最快的速度寻址：不遗漏一个字节，也不重复对一个字节寻址。

**对于程序来说，一个变量最好位于一个寻址步长的范围内，这样一次就可以读取到变量的值；如果跨步长存储，就需要读取两次，然后再拼接数据，效率显然降低了。**

例如一个 int 类型的数据，如果地址为 8，那么很好办，对编号为 8 的内存寻址一次就可以。如果编号为 10，就比较麻烦，CPU需要先对编号为 8 的内存寻址，读取4个字节，得到该数据的前半部分，然后再对编号为 12 的内存寻址，读取4个字节，得到该数据的后半部分，再将这两部分拼接起来，才能取得数据的值。

**将一个数据尽量放在一个步长之内，避免跨步长存储，这称为内存对齐。**在32位编译模式下，默认以4字节对齐；在64位编译模式下，默认以8字节对齐。

为了提高存取效率，编译器会自动进行内存对齐，请看下面的代码：

```cpp
#include <stdio.h>
#include <stdlib.h>
 
struct{
    int a;
    char b;
    int c;
}t={ 10, 'C', 20 };
 
int main()
{
    printf("length: %d\n", sizeof(t));
    printf("&a: %X\n&b: %X\n&c: %X\n", &t.a, &t.b, &t.c);
    system("pause");
    return 0;
}
```

在32位编译模式下的运行结果：

```
length: 12
&a: B69030
&b: B69034
&c: B69038
```

如果不考虑内存对齐，结构体变量 t 所占内存应该为 4+1+4 = 9 个字节。考虑到内存对齐，虽然成员 b 只占用1个字节，但它所在的寻址步长内还剩下 3 个字节的空间，放不下一个 int 型的变量了，所以**要把成员 c 放到下一个寻址步长。剩下的这3个字节，作为内存填充浪费掉了**。请看下图：

![img](https://img-blog.csdnimg.cn/img_convert/b7ca85545bdf8d0f83d20e0d297dc0d5.png)

**编译器之所以要内存对齐，是为了更加高效的存取成员 c，而代价就是浪费了3个字节的空间。**

除了结构体，变量也会进行内存对齐，请看下面的代码：

```cpp
#include <stdio.h>
#include <stdlib.h>
 
int m;
char c;
int n;
 
int main()
{
    printf("&m: %X\n&c: %X\n&n: %X\n", &m, &c, &n);
    system("pause");
    return 0;
}
```

在VS下运行：

```
&m: DE3384
&c: DE338C
&n: DE3388
```

可见它们的地址都是4的整数倍，并相互挨着。

经过笔者测试，对于全局变量，GCC在 Debug 和 Release 模式下都会进行内存对齐，而VS只有在 Release 模式下才会进行对齐。而对于局部变量，GCC和VS都不会进行对齐，不管是Debug模式还是Release模式。

## 改变对齐方式

**内存对齐虽然和硬件有关，但是决定对齐方式的是编译器，如果你的硬件是64位的，却以32位的方式编译，那么还是会按照4个字节对齐。**

### 直接使用IDE改变对齐方式

对齐方式可以通过编译器参数修改，以VS2010为例，更改对齐方式的步骤为：

```
项目 --> 属性 --> C/C++ --> 代码生成 --> 结构成员对齐
```

如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/d6f771f9aa5a1bf73b5eb010c64c0254.png)

### 在程序中**改变对齐方式**

结构体内存对齐字节也可以通过**#pragma pack(n)** 的方式来指定，我们首先了解一下对齐模数。

**许多实际的计算机系统对基本类型数据在内存中存放的位置有限制，它们会要求这些数据的起始地址的值是某个数k的倍数，而这个k则被称为该数据类型的对齐模数(alignment modulus)。这种强制的要求一来简化了处理器与内存之间传输系统的设计，二来可以提升读取数据的速度。**

比如这么一种处理器，它每次读写内存的时候都从某个8倍数的地址开始，一次读出或写入8个字节的数据，假如软件能保证double类型的数据都从8倍数地址开始，那么读或写一个double类型数据就只需要一次内存操作。否则，我们就可能需要两次内存操作才能完成这个动作，因为数据或许恰好横跨在两个符合对齐要求的8字节内存块上。

其次需要明确各个数据成员的对齐模数，对齐模数和数据成员本身的长度以及pragma pack编译参数有关，其值是二者中最小数。如果程序没有明确指出，就需要知道编译器默认的对齐模数值。下表是Windows XP/DEV-C++和Linux/GCC中基本数据类型的长度和默认对齐模数。

|          |      | char | short | int  | long | float | double | long long | long double |
| -------- | ---- | ---- | ----- | ---- | ---- | ----- | ------ | --------- | ----------- |
| Win-32   | 长度 | 1    | 2     | 4    | 4    | 4     | 8      | 8         | 8           |
| 模数     | 1    | 2    | 4     | 4    | 4    | 8     | 8      | 8         |             |
| Linux-32 | 长度 | 1    | 2     | 4    | 4    | 4     | 8      | 8         | 12          |
| 模数     | 1    | 2    | 4     | 4    | 4    | 4     | 4      | 4         |             |
| Linux-64 | 长度 | 1    | 2     | 4    | 8    | 4     | 8      | 8         | 16          |
| 模数     | 1    | 2    | 4     | 8    | 4    | 8     | 8      | 16        |             |

请看以下例子： 

```cpp
struct struct_demo 
{ 
    char a; 
    long double b; 
};
```

此例子Windows和Linux结构体长度计算方法有些许不一致。

**在Win-32中计算步骤如下：**

A、char成员的长度为1B、long double成员的长度为8B，char成员的模数为1、long double成员的模数为8；

B、所有数据成员自身长度和：

```
1B + 8B = 9B
```

C、数据成员a放在相对偏移0处，之前不需要填充字节；数据成员b为了内存对齐，其对齐模数默认最大值8，所以之前需填充7个字节：

```
9B + 7B = 16B
```

D、按照之前说的原则，结构体对齐模数是结构体内部最大数据成员长度和pragma pack中较小者，前者为8（long double成员的模数）后者为4（Win-32系统），所以结构体对齐模数是4。sum_b是4的4倍，不需再次对齐。

综上4步，可知结构体的长度是16B，各数据成员在内存中的分布如图1-1所示。

**同理在Linux-32中计算步骤如下：**

A、所有数据成员自身长度和：

```
1B + 12B = 13B；
```

B、数据成员a放在相对偏移0处，之前不需要填充字节；数据成员b为了内存对齐，其对齐模数是4，之前需填充3个字节：

```
13B + 3B = 16B
```

C、按照定义，结构体对齐模数是结构体内部最大数据成员长度和pragma pack中较小者，前者为12后者为4，所以结构体对齐模数是4。sum_b是4的4倍，不需再次对齐。

综上可知结构体的长度是16B，各数据成员在内存中的分布如图1-2所示。


![1-1](https://img-blog.csdnimg.cn/img_convert/14069a94be8dbf14e0f43916c2097d72.png)

其实在以上32位操作系统中，我们可以认为在程序中制定了 **#pragma pack(4)**，只不过隐式指定而已，下面我们看看**#pragma pack的使用方法。**

以下演示环境为Linux-64：

```cpp
#include <stdio.h>
 
#pragma pack(2) 
#pragma pack(push) 
#pragma pack(4) 
struct CC {
    double d;
    char b;
    int a;
    short c;
};
 
#pragma pack(1) 
struct BB{
    double d;
    char b;
    int a;
    short c;
};
 
#pragma pack(pop)
struct AA{
    double d;
    char b;
    int a;
    short c;
};
 
int main(void)
{   
    printf("%u\n%u\n%u\n",sizeof(struct CC),sizeof(struct BB),sizeof(struct AA));
    return 0;
}
```

打印如下：

```
20
15
16
```

为何打印结果是如此呢？

**这是因为程序先按照2字节对齐，然后push保存2字节对齐，然后又强制4字节对齐，打印CC为20字节（8+4+4+4），然后强制1字节对齐，打印BB为15字节（8+1+4+2），然后pop，pop会让编译器回到push之前的对齐方式（这里是2字节对齐），打印AA（按照2字节对齐）16字节（8+2+4+2）。 注意：#pragma pack(push)与#pragma pack(pop)就像保存临时变量的堆栈！另外#pragma pack() 取消自定义对齐方式，恢复默认方式，而push之后pop是回到push指令之前的对齐方式。**

除了这种方法，还有另外一种，我们有时候在kernel或者uboot源码中可能会遇到：

- **__attribute(aligned(n))，让所作用的数据成员对齐在n字节的自然边界上；如果结构中有成员的长度大于n，则按照最大成员的长度来对齐；**
- **__attribute((packed))，取消结构在编译过程中的优化对齐，按照实际占用字节数进行对齐。**

最后需要说明的是：**内存对齐不是C语言的特性，它属于计算机的运行原理，C++、Java、Python等其他编程语言同样也会有内存对齐的问题**。

# 内存分页

## 内存映射

假设我们以程序为单位，把一段与程序运行所需要的同等大小的虚拟空间映射到某段物理空间。

例如程序A需要 10MB 内存，虚拟地址的范围是从 0X00000000 到 0X00A00000，假设它被映射到一段同等大小的物理内存，地址范围从 0X00100000 到 0X00B00000，即虚拟空间中的每一个字节对应于物理空间中的每一个字节。

程序运行时，它们的对应关系如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/01faa5da67b8f854d4eb07f92d8753af.webp)

当程序A需要访问 0X00001000 时，系统会将这个虚拟地址转换成实际的物理地址 0X00101000，访问 0X002E0000 时，转换成 0X003E0000，以此类推。

这种以整个程序为单位的方法很好地解决了不同程序地址不隔离的问题，同时也能够在程序中使用固定的地址。

### 地址隔离

如之前图所示，程序A和程序B分别被映射到了两块不同的物理内存，它们之间没有任何重叠，如果程序A访问的虚拟地址超出了 0X00A00000 这个范围，系统就会判断这是一个非法的访问，拒绝这个请求，并将这个错误报告给用户，通常的做法就是强制关闭程序。

### 程序可以使用固定的内存地址

虚拟内存无论被映射到物理内存的哪一个区域，对于程序员来说都是透明的，我们不需要关心物理地址的变化，只需要按照从地址 0X00000000 到 0X00A00000 来编写程序、放置变量即可，程序不再需要重定位。

### 内存使用效率问题

以程序为单位对虚拟内存进行映射时，如果物理内存不足，被换入换出到磁盘的是整个程序，这样势必会导致大量的磁盘读写操作，严重影响运行速度，所以这种方法还是显得粗糙，粒度比较大。

## 内存分页机制

我们知道，当一个程序运行时，在某个时间段内，它只是频繁地用到了一小部分数据，也就是说，程序的很多数据其实在一个时间段内都不会被用到。

以整个程序为单位进行映射，不仅会将暂时用不到的数据从磁盘中读取到内存，也会将过多的数据一次性写入磁盘，这会严重降低程序的运行效率。

现代计算机都使用**分页（Paging）的方式对虚拟地址空间和物理地址空间进行分割和映射，以减小换入换出的粒度**，提高程序运行效率。

**分页（Paging）的思想是指把地址空间人为地分成大小相等（并且固定）的若干份，这样的一份称为一页**，就像一本书由很多页面组成，每个页面的大小相等。如此，就能够以页为单位对内存进行换入换出：

- **当程序运行时，只需要将必要的数据从磁盘读取到内存，暂时用不到的数据先留在磁盘中，什么时候用到什么时候读取。**
- **当物理内存不足时，只需要将原来程序的部分数据写入磁盘，腾出足够的空间即可，不用把整个程序都写入磁盘。**

### 关于页的大小

**页的大小是固定的，由硬件决定，或硬件支持多种大小的页，由操作系统选择决定页的大小。**比如 Intel Pentium 系列处理器支持 4KB 或 4MB 的页大小，那么操作系统可以选择每页大小为 4KB，也可以选择每页大小为 4MB，但是在同一时刻只能选择一种大小，所以对整个系统来说，也就是固定大小的。

**目前几乎所有PC上的操作系统都是用 4KB 大小的页。**假设我们使用的PC机是32位的，那么虚拟地址空间总共有 4GB，按照 4KB 每页分的话，总共有 2^32 / 2^12 = 2^20 = 1M = 1048576 个页；物理内存也是同样的分法。

### 根据页进行映射

下面我们通过一个简单的例子来说明虚拟地址是如何根据页来映射到物理地址的，请先看下图：

![img](https://img-blog.csdnimg.cn/img_convert/ab6fad6cb1a108aab0867dd866fbc30f.webp)

程序1和程序2的虚拟空间都有8个页，为了方便说明问题，我们假设每页大小为 1KB，那么虚拟地址空间就是 8KB。假设计算机有13条地址线，即拥有 2^13 的物理寻址能力，那么理论上物理空间可以多达 8KB。但是出于种种原因，购买内存的资金不够，只买得起 6KB 的内存，所以物理空间真正有效的只是前 6KB。

当我们把程序的虚拟空间按页分隔后，把常用的数据和代码页加载到内存中，把不常用的暂时留在磁盘中，当需要用到的时候再从磁盘中读取。上图中，我们假设有两个程序 Program 1 和 Program 2，它们的部分虚拟页面被映射到物理页面，比如 Program 1 的 VP0、VP1 和 VP7 分别被映射到 PP0、PP2 和 PP3；而有部分却留在磁盘中，比如 VP2、VP3 分别位于磁盘的 DP0、DP1中；另外还有一些页面如 VP4、VP5、VP6 可能尚未被用到或者访问到，它们暂时处于未使用状态。

这里，我们**把虚拟空间的页叫做虚拟页（VP，Virtual Page），把物理内存中的页叫做物理页（PP，Physical Page），把磁盘中的页叫做磁盘页（DP，Disk Page）**。

图中的线表示映射关系，可以看到，Program 1 和 Program 2 中的有些虚拟页被映射到同一个物理页，这样可以实现内存共享。

Program 1 的 VP2、VP3 不在内存中，但是当进程需要用到这两个页的时候，硬件会捕获到这个消息，就是所谓的**页错误（Page Fault）**，然后操作系统接管进程，负责将 VP2 和 VP3 从磁盘中读取出来并且装入内存，然后将内存中的这两个页与 VP2、VP3 之间建立映射关系。

## 内存分页实现

现代操作系统都使用分页机制来管理内存，这使得每个程序都拥有自己的地址空间。每当程序使用虚拟地址进行读写时，都必须转换为实际的物理地址，才能真正在内存条上定位数据。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/c469ad4d80f2efcc46976fbd7832fe28.png)


**内存地址的转换是通过一种叫做页表（Page Table）的机制来完成的**，那么这里提几个问题：

- 页表是什么？为什么要采用页表机制，而不采用其他机制？
- 虚拟地址如何通过页表转换为物理地址？

### 直接使用数组转换

最容易想到的映射方案是使用数组：**每个数组元素保存一个物理地址，而把虚拟地址作为数组下标**，这样就能够很容易地完成映射，并且效率不低。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/325f438b05476afd17d2926b665c434f.png)


但是这样的数组有 2^32 个元素，每个元素大小为4个字节，总共占用16GB的内存，显现是不现实的！

### 使用一级页表

既然内存是分页的，只要我们能够定位到数据所在的页，以及它在页内的偏移（也就是距离页开头的字节数），就能够转换为物理地址。例如，一个 int 类型的值保存在第 12 页，页内偏移为 240，那么对应的物理地址就是 2^12 * 12 + 240 = 49392。

**2^12 为一个页的大小，也就是4K。**

虚拟地址空间大小为 4GB，总共包含 2^32 / 2^12 = 2^20 = 1K * 1K  = 1M = 1048576 个页面，我们可以定义一个这样的数组：它包含 2^20 = 1M 个元素，每个元素的值为**页面编号（也就是位于第几个页面）**，长度为4字节，整个数组共占用4MB的内存空间。这样的数组就称为**页表（Page Table）**，它记录了**地址空间中所有页的编号**。

虚拟地址长度为32位，我们不妨进行一下切割，将高20位作为页表数组的下标，低12位作为页内偏移。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/c4e86c251aa4b0a84a8dac7f039baa1b.png)


为什么要这样切割呢？**因为页表数组共有 2^20 = 1M 个元素，使用虚拟地址的高20位作为下标，正好能够访问数组中的所有元素；并且，一个页面的大小为 2^12 = 4KB，使用虚拟地址的低12位恰好能够表示所有偏移。**

注意，表示页面编号只需要 20 位，而页表数组的每个元素的长度却为 4 字节，即 32 位，多出 32 - 20 = 12 位。这 12 位也有很大的用处，可以用来表示当前页的相关属性，例如是否有读写权限、是否已经分配物理内存、是否被换出到硬盘等。

例如一个虚拟地址 0XA010BA01，它的高20位是 0XA010B，所以需要访问页表数组的第 0XA010B 个元素，才能找到数据所在的物理页面。假设页表数组第 0XA010B 个元素的值为 0X0F70AAA0，它的高20位为 0X0F70A，那么就可以确定数据位于第 0X0F70A 个物理页面。再来看虚拟地址，它的低12位是 0XA01，所以页内偏移也是 0XA01。有了页面索引和页内偏移，就可以算出物理地址了。经过计算，最终的物理地址为 0X0F70A * 2^12 + 0XA01 = 0X0F70A000 + 0XA01 = 0X0F70AA01。

这种思路所形成的映射关系如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/0290b5f97c0a15d2931667e2fb7671d6.png)


可以发现，有的页被映射到物理内存，有的被映射到硬盘，**不同的映射方式可以由页表数组元素的低12位来控制**。

使用这种方案，不管程序占用多大的内存，都要为页表数组分配4M的内存空间（**页表数组也必须放在物理内存中**），因为虚拟地址空间中的高1G或2G是被系统占用的，必须保证较大的数组下标有效。

现在硬件很便宜了，内存容量大了，很多电脑都配备4G或8G的内存，页表数组占用4M内存或许不觉得多，但在32位系统刚刚发布的时候，内存还是很紧缺的资源，很多电脑才配备100M甚至几十兆的内存，4M内存就显得有点大了，所以还得对上面的方案进行改进，压缩页表数组所占用的内存。

### 使用两级页表

上面的页表共有 2^20 = 2^10 * 2^10 个元素，为了压缩页表的存储空间，可以将上面的页表分拆成 2^10 = 1K = 1024 个小的页表，这样每个页表只包含 2^10 = 1K = 1024 个元素，占用 2^10 * 4 = 4KB 的内存，也即一个页面的大小。这 1024 个小的页表，可以存储在不同的物理页，它们之间可以是不连续的。

那么问题来了，既然这些小的页表分散存储，位于不同的物理页，该如何定位它们呢？也就是如何记录它们的编号（也即在物理内存中位于第几个页面）。

1024 个页表有 1024 个索引，所以不能用一个指针指向它们，必须将这些索引再保存到一个额外的数组中。这个额外的数组有1024个元素，每个元素记录一个页表所在物理页的编号，长度为4个字节，总共占用4KB的内存。我们将这个额外的数组称为**页目录（Page Directory）**，因为它的每一个元素对应一个页表。

如此，**只要使用一个指针来记住页目录的地址即可，等到进行地址转换时，可以根据这个指针找到页目录，再根据页目录找到页表，最后找到物理地址，前后共经过3次间接转换**。

那么，如何根据虚拟地址找到页目录和页表中相应的元素呢？我们不妨将虚拟地址分割为三分部，高10位作为页目录中元素的下标，中间10位作为页表中元素的下标，最后12位作为页内偏移，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/e3c49dc2279918c168fd56118556dc52.png)


前面我们说过，知道了物理页的索引和页内偏移就可以转换为物理地址了，在这种方案中，页内偏移可以从虚拟地址的低12位得到，但是物理页索引却保存在 1024 个分散的小页表中，所以就必须先根据页目录找到对应的页表，再根据页表找到物理页索引。

例如一个虚拟地址 0011000101  1010001100  111100001010，它的高10位为 0011000101，对应页目录中的第 0011000101 个元素，假设该元素的高20位为 0XF012A，也即对应的页表在物理内存中的编号为 0XF012A，这样就找到了页表。虚拟地址中间10位为 1010001100，它对应页表中的第 1010001100 个元素，假设该元素的高20位为 0X00D20，也即物理页的索引为 0X00D20。通过计算，最终的物理地址为 0X00D20 * 2^12 + 111100001010 = 0X00D20F0A。

这种思路所形成的映射关系如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/aea13fc430c343fd4f0b7a3629726c19.png)

**图中的点状虚线说明了最终的映射关系。图中没有考虑映射到硬盘的情况。**


采用这样的两级页表的一个明显优点是，如果程序占用的内存较少，分散的小页表的个数就会远远少于1024个，只会占用很少的一部分存储空间（远远小于4M）。

在极少数的情况下，程序占用的内存非常大，布满了4G的虚拟地址空间，这样小页表的数量可能接近甚至等于1024，再加上页目录占用的存储空间，总共是 4MB+4KB，比上面使用一级页表的方案仅仅多出4KB的内存。这是可以容忍的，因为很少出现如此极端的情况。

也就是说，使用两级页表后，页表占用的内存空间不固定，它和程序本身占用的内存空间成正比，从整体上来看，会比使用一级页表占用的内存少得多。

### 使用多级页表

对于64位环境，虚拟地址空间达到 256TB，使用二级页表占用的存储空间依然不小，所以会更加细化，从而使用三级页表甚至多级页表，这样就会有多个页目录，虚拟地址也会被分割成多个部分，思路和上面是一样的，不再赘述。

# MMU&内存权限

通过页表完成虚拟地址和物理地址的映射时，要经过多次转换，还要进行计算，如果由操作系统来完成这项工作，那将会成倍降低程序的性能，得不偿失，所以这种方式是不现实的。

## MMU

在CPU内部，有一个部件叫做MMU（Memory Management Unit，内存管理单元），由它来负责将虚拟地址映射为物理地址，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/c0c7ddb47d2eec033358dc6012bce95a.png)


在页映射模式下，CPU 发出的是虚拟地址，也就是我们在程序中看到的地址，这个地址会先交给 MMU，经过 MMU 转换以后才能变成了物理地址。

即便是这样，MMU也要访问好几次内存，性能依然堪忧，所以在MMU内部又增加了一个**缓存**，**专门用来存储页目录和页表**。MMU内部的缓存有限，当页表过大时，也只能将部分常用页表加载到缓存，但这已经足够了，因为经过算法的巧妙设计，可以将缓存的命中率提高到 90%，剩下的10%的情况无法命中，再去物理内存中加载页表。

有了硬件的直接支持，使用虚拟地址和使用物理地址相比，损失的性能已经很小，在可接受的范围内。

**MMU 只是通过页表来完成虚拟地址到物理地址的映射，但不会构建页表，构建页表是操作系统的任务。**在程序加载到内存以及程序运行过程中，操作系统会不断更新程序对应的页表，并将**页目录的物理地址**保存到 **CR3 寄存器**。MMU 向缓存中加载页表时，会根据 CR3 寄存器找到页目录，再找到页表，最终通过软件和硬件的结合来完成内存映射。

**CR3 是CPU内部的一个寄存器，专门用来保存页目录的物理地址。**

每个程序在运行时都有自己的一套页表，切换程序时，只要改变 CR3 寄存器的值就能够切换到对应的页表。

## 对内存权限的控制

MMU 除了能够完成虚拟地址到物理地址的映射，还能够对内存权限进行控制。在页表数组中，若每个元素占用4个字节，也即32位，我们使用高20位来表示物理页编号，还剩下低12位，这12位就用来对内存进行控制，例如，**是映射到物理内存还是映射到磁盘，程序有没有访问权限，当前页面有没有执行权限**等。

操作系统在构建页表时将内存权限定义好，当MMU对虚拟地址进行映射时，首先检查低12位，看当前程序是否有权限使用，如果有，就完成映射，如果没有，就产生一个异常，并交给操作系统处理。操作系统在处理这种内存错误时一般比较粗暴，会直接终止程序的执行。

请看下面的代码：

```cpp
#include <stdio.h>
 
int main()
{
    char *str = (char*)0XFFF00000;  //使用数值表示一个明确的地址
    printf("%s\n", str);
    return 0;
}
```

这段代码不会产生编译和链接错误，但在运行程序时，为了输出字符串，printf() 需要访问虚拟地址为 0XFFFF00000 的内存，但是该虚拟地址是被操作系统占用的，程序没有权限访问，会被强制关闭，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/a6f239be6685cc2782a250f72cea3a38.png)


而在Linux下，会产生**段错误（Segment Fault）**，相信大家在编程过程中会经常见到这种经典的内存错误。

# 内存模型

虚拟地址空间在32位环境下的大小为 4GB，在64位环境下的大小为 256TB，那么，一个C语言程序的内存在整个地址空间中是如何分布的呢？数据在哪里？代码在哪里？为什么要这样分布？

程序内存在地址空间中的分布情况称为**内存模型（Memory Model）**。内存模型由操作系统构建，在Linux和Windows下有所差异，并且会受到编译模式的影响。

## 内核空间和用户空间

对于32位环境，理论上程序可以拥有 4GB 的虚拟地址空间，我们在C语言中使用到的变量、函数、字符串等都会对应内存中的一块区域。

但是，在这 4GB 的地址空间中，要拿出一部分给操作系统内核使用，应用程序无法直接访问这一段内存，这一部分内存地址被称为**内核空间（Kernel Space）**。

**Windows 在默认情况下会将高地址的 2GB 空间分配给内核（也可以配置为1GB），而 Linux 默认情况下会将高地址的 1GB 空间分配给内核。也就是说，应用程序只能使用剩下的 2GB 或 3GB 的地址空间，称为用户空间（User Space）。**

## Linux下32位环境的用户空间内存分布情况

我们暂时不关心内核空间的内存分布情况，下图是Linux下32位环境的一种经典内存模型：

![img](https://img-blog.csdnimg.cn/img_convert/9ec3caa588b4ec6a6055575420f065ff.png)


对各个内存分区的说明：

| 内存分区                 | 说明                                                         |
| :----------------------- | :----------------------------------------------------------- |
| 程序代码区 (code)        | 存放函数体的二进制代码。一个C语言程序由多个函数构成，C语言程序的执行就是函数之间的相互调用。 |
| 常量区 (constant)        | 存放一般的常量、字符串常量等。这块内存只有读取权限，没有写入权限，因此它们的值在程序运行期间不能改变。 |
| 全局数据区 (global data) | 存放全局变量、静态变量等。这块内存有读写权限，因此它们的值在程序运行期间可以任意改变。 |
| 堆区 (heap)              | 一般由程序员分配和释放，若程序员不释放，程序运行结束时由操作系统回收。malloc()、calloc()、free() 等函数操作的就是这块内存。  注意：这里所说的堆区与数据结构中的堆不是一个概念，堆区的分配方式倒是类似于链表。 |
| 动态链接库               | 用于在程序运行期间加载和卸载动态链接库。                     |
| 栈区 (stack)             | 存放函数的参数值、局部变量的值等，其操作方式类似于数据结构中的栈。 |


在这些内存分区中（暂时不讨论动态链接库），**程序代码区用来保存指令，常量区、全局数据区、堆、栈都用来保存数据**。对内存的研究，重点是对数据分区的研究。

程序代码区、常量区、全局数据区在程序加载到内存后就分配好了，并且在程序运行期间一直存在，不能销毁也不能增加（大小已被固定），只能等到程序运行结束后由操作系统收回，所以全局变量、字符串常量等在程序的任何地方都能访问，因为它们的内存一直都在。

**常量区和全局数据区有时也被合称为静态数据区，意思是这段内存专门用来保存数据，在程序运行期间一直存在。**

函数被调用时，会将参数、局部变量、返回地址等与函数相关的信息压入栈中，函数执行结束后，这些信息都将被销毁。所以局部变量、参数只在当前函数中有效，不能传递到函数外部，因为它们的内存不在了。

**常量区、全局数据区、栈上的内存由系统自动分配和释放，不能由程序员控制。**程序员唯一能控制的内存区域就是堆（Heap）：它是一块巨大的内存空间，常常占据整个虚拟空间的绝大部分，在这片空间中，程序可以申请一块内存，并自由地使用（放入任何数据）。堆内存在程序主动释放之前会一直存在，不随函数的结束而失效。**在函数内部产生的数据只要放到堆中，就可以在函数外部使用。**

## 一个实例

为了加深对内存布局的理解，请大家看下面一段代码：

```cpp
#include <stdio.h>
 
char *str1 = "blog.csdn.net";  //字符串在常量区，str1在全局数据区
int n;  //全局数据区
 
char* func()
{
    char *str = "neutionwei";  //字符串在常量区，str在栈区
    return str;
}
 
int main()
{
    int a;  //栈区
    char *str2 = "01234";  //字符串在常量区，str2在栈区
    char  arr[20] = "56789";  //字符串和arr都在栈区
    char *pstr = func();  //栈区
    int b;  //栈区
    printf("str1: %#X\npstr: %#X\nstr2: %#X\n", str1, pstr, str2);
    puts("--------------");
    printf("&str1: %#X\n   &n: %#X\n", &str1, &n);
    puts("--------------");
    printf("  &a: %#X\n arr: %#X\n  &b: %#X\n", &a, arr, &b);
    puts("--------------");
    printf("n: %d\na :%d\nb: %d\n", n, a, b);
    puts("--------------");
    printf("%s\n", pstr);
    return 0;
}
```

运行结果：

```cpp
str1: 0X400710
pstr: 0X400720
str2: 0X400731
--------------
&str1: 0X601040
   &n: 0X60104C
--------------
 &a: 0X19D0728C
arr: 0X19D07270
 &b: 0X19D0726C
--------------
n: 0
a: -858993460
b: -858993460
--------------
neutionwei
```

对代码的说明：

（1）全局变量的内存在编译时就已经分配好，它的默认初始值是 0（它所占用的每一个字节都是0值），局部变量的内存在函数调用时分配，它默认初始值是不确定的，由编译器决定，一般是垃圾值。

（2）函数 func() 中的局部字符串常量`"neutionwei"`也被存储到常量区，不会随着 func() 的运行结束而销毁，所以最后依然能够输出。

（3）字符数组 arr[20] 在栈区分配内存，字符串`"56789"`也保存在这块内存中，而不是在常量区，大家要注意区分。

## Linux下64位环境的用户空间内存分布情况

在64位环境下，虚拟地址空间大小为 256TB，Linux 将高 128TB 的空间分配给内核使用，而将低 128TB 的空间分配给用户程序使用。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/f2cf37315b36d6db231cefc152f66be5.png)


在64位环境下，虚拟地址虽然占用64位，但只有最低48位有效。这里需要补充的一点是，**任何虚拟地址的48位至63位必须与47位一致**。

上图中，用户空间地址值的第47位是0，所以高16位也是0，换算成十六进制形式，最高的四个数都是0；内核空间地址值的第47位是1，所以高16位也是1，换算成十六进制形式，最高的四个数都是1。这样中间的一部分地址正好空出来，也就是图中的“未定义区域”，这部分内存无论如何也访问不到。

# 用户模式&内核模式

首先我们要解释一个概念——进程（Process）。简单来说，**一个可执行程序就是一个进程**，我们使用C语言编译生成的程序，运行后就是一个进程。进程最显著的特点就是**拥有独立的地址空间**。

严格来说，程序是存储在磁盘上的一个文件，是指令和数据的集合，是一个**静态**的概念；进程是程序加载到内存运行后一系列的活动，是一个**动态**的概念。

“程序的地址空间”的说法，这其实是不严谨的，应该说“进程的地址空间”。**一个进程对应一个地址空间，而一个程序可能会创建多个进程**。

## 内核模式和用户模式

内核空间存放的是**操作系统内核代码和数据**，是被所有程序**共享**的，在程序中修改内核空间中的数据不仅会影响操作系统本身的稳定性，还会影响其他程序，这是非常危险的行为，所以操作系统禁止用户程序直接访问内核空间。

要想访问内核空间，必须借助操作系统提供的 API 函数，执行内核提供的代码，让内核自己来访问，这样才能保证内核空间的数据不会被随意修改，才能保证操作系统本身和其他程序的稳定性。

**用户程序调用系统 API 函数称为系统调用（System Call）；发生系统调用时会暂停用户程序，转而执行内核代码（内核也是程序），访问内核空间，这称为内核模式（Kernel Mode）。**

**用户空间保存的是应用程序的代码和数据，是程序私有的，其他程序一般无法访问。当执行应用程序自己的代码时，称为用户模式（User Mode）。**

计算机会经常在内核模式和用户模式之间切换：

- **当运行在用户模式的应用程序需要输入输出、申请内存等比较底层的操作时，就必须调用操作系统提供的 API 函数，从而进入内核模式；**
- **操作完成后，继续执行应用程序的代码，就又回到了用户模式。**

总结：**用户模式就是执行应用程度代码，访问用户空间；内核模式就是执行内核代码，访问内核空间（当然也有权限访问用户空间）。**

## 为什么要区分两种模式

内核最主要的任务是**管理硬件**，包括显示器、键盘、鼠标、内存、硬盘等，并且内核也提供了接口（也就是函数），供上层程序使用。当程序要进行输入输出、分配内存、响应鼠标等与硬件有关的操作时，必须要使用内核提供的接口。但是用户程序是非常不安全的，内核对用户程序也是充分不信任的，当程序调用内核接口时，内核要做各种校验，以防止出错。

从 Intel 80386 开始，出于安全性和稳定性的考虑，CPU 可以**运行在 ring0 ~ ring3 四个不同的权限级别**，也对数据提供相应的四个保护级别。不过 Linux 和 Windows 只利用了其中的两个运行级别：

- **一个是内核模式，对应 ring0 级，操作系统的核心部分和设备驱动都运行在该模式下。**
- **一个是用户模式，对应 ring3 级，操作系统的用户接口部分（例如 Windows API）以及所有的用户程序都运行在该级别。**

## 为什么内核和用户程序要共用地址空间

既然内核也是一个程序，为何不让它拥有独立的4GB地址空间，而是要和用户程序共享、占用有限的内存呢？

**让内核拥有完全独立的地址空间，就是让内核处于一个独立的进程中，这样每次进行系统调用都需要切换进程。切换进程的消耗是巨大的，不仅需要寄存器进栈出栈，还会使CPU中的数据缓存失效、MMU中的页表缓存失效，这将导致内存的访问在一段时间内相当低效。**

而让内核和用户程序共享地址空间，发生系统调用时进行的是模式切换，模式切换仅仅需要寄存器进栈出栈，不会导致缓存失效；现代CPU也都提供了快速进出内核模式的指令，与进程切换比起来，效率大大提高了。

# 栈&栈溢出

程序的虚拟地址空间分为多个区域，栈（Stack）是其中地址较高的一个区域。**栈（Stack）可以存放函数参数、局部变量、局部数组等作用范围在函数内部的数据，它的用途就是完成函数的调用**。

**栈内存由系统自动分配和释放**：发生函数调用时就为函数运行时用到的数据分配内存，函数调用结束后就将之前分配的内存全部销毁。所以局部变量、参数只在当前函数中有效，不能传递到函数外部。

## 栈的概念

在计算机中，栈可以理解为一个特殊的容器，用户可以将数据依次放入栈中，然后再将数据按照相反的顺序从栈中取出。也就是说，先放入的数据最后才能取出，而最后放入的数据必须先取出。这称为**先进后出（First In Last Out）原则**。

**放入数据常称为入栈或压栈（Push），取出数据常称为出栈或弹出（Pop）**。如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/59d0f7e08304f37a425c6f821b18e2a3.png)

可以发现，栈底始终不动，出栈入栈只是在移动栈顶，**当栈中没有数据时，栈顶和栈底重合**。

从本质上来讲，栈是一段连续的内存，需要同时记录栈底和栈顶，才能对当前的栈进行定位。在现代计算机中，通常**使用`ebp`寄存器指向栈底，而使用`esp`寄存器指向栈顶**。随着数据的进栈出栈，esp 的值会不断变化，进栈时 esp 的值减小，出栈时 esp 的值增大。

**ebp 和 esp 都是CPU中的寄存器：ebp 是 Extend Base Pointer 的缩写，通常用来指向栈底；esp 是 Extend Stack Pointer 的缩写，通常用来指向栈顶。**

如下图所示是一个栈的实例：

![img](https://img-blog.csdnimg.cn/img_convert/50829b7577e1ecb191d78055af26167f.png)

## 栈的大小以及栈溢出

对每个程序来说，栈能使用的内存是有限的，一般是 1M~8M，这在编译时就已经决定了，程序运行期间不能再改变。如果程序使用的栈内存超出最大值，就会发生栈溢出（Stack Overflow）错误。

**一个程序可以包含多个线程，每个线程都有自己的栈，严格来说，栈的最大值是针对线程来说的，而不是针对程序。**

**栈内存的大小和编译器有关，编译器会为栈内存指定一个最大值，在 VC/VS 下，默认是 1M，在 C-Free 下，默认是 2M，在 Linux GCC 下，默认是 8M。**

当然，我们也可以通过参数来修改栈内存的大小。以 VS2010 为例，在工程名处右击，会弹出一个菜单，选择“属性”，会出现一个对话框，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/316ec802c34c462212f9472d737acc89.png)

该图中，我们将栈内存设置为 4M。提示：**栈也经常被称为堆栈，而堆依然称为堆，所以堆栈这个概念并不包含堆**，大家要注意区分。

当程序使用的栈内存大于默认值（或者修改后的值）时，就会发生**栈溢出（Stack Overflow）**错误。使用 VS2010 并切换到 Debug 模式，运行如下的代码：

```cpp
int main()



{



    char str[1024*1024*2] = {0};



    return 0;



}
```

局部字符数组 str 存储在栈上，占用 2M 的内存，超出了默认值 1M，所以会发生栈溢出错误，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/1cd8a9260eb0069828d9d0632e68ed83.png)

# 函数在栈上的调用

函数的调用和栈是分不开的，没有栈就没有函数调用，我们就来学习函数在栈上是如何被调用的。

## 栈帧/活动记录

**当发生函数调用时，会将函数运行需要的信息全部压入栈中，这常常被称为栈帧（Stack Frame）或活动记录（Activate Record）**。活动记录一般包括以下几个方面的内容：

（1）**函数的返回地址**，也就是函数执行完成后从哪里开始继续执行后面的代码。例如：

```cpp
int a, b, c;



func(1, 2);



c = a + b;
```

站在C语言的角度看，func() 函数执行完成后，会继续执行`c=a+b;`语句，那么返回地址就是该语句在内存中的位置。

**注意：C语言代码最终会被编译为机器指令，确切地说，返回地址应该是下一条指令的地址**，这里之所以说是下一条C语言语句的地址，仅仅是为了更加直观地说明问题。

（2）**参数和局部变量**。有些编译器，或者编译器在开启优化选项的情况下，会通过寄存器来传递参数，而不是将参数压入栈中，我们暂时不考虑这种情况。

（3）**编译器自动生成的临时数据**。例如，当函数返回值的长度较大（比如占用40个字节）时，会先将返回值压入栈中，然后再交给函数调用者。

**当返回值的长度较小（char、int、long 等）时，不会被压入栈中，而是先将返回值放入寄存器，再传递给函数调用者。**

（4）**一些需要保存的寄存器，例如 ebp、ebx、esi、edi 等**。之所以要保存寄存器的值，是为了在函数退出时能够恢复到函数调用之前的场景，继续执行上层函数。

下图是一个函数调用的实例：

![img](https://img-blog.csdnimg.cn/img_convert/32c0560c249cc1c070cf0c0d55583319.png)


上图是在Windows下使用VS2010 Debug模式编译时一个函数所使用的栈内存，可以发现，理论上 ebp 寄存器应该指向栈底，但在实际应用中，它却指向了old ebp。

**在寄存器名字前面添加“old”，表示函数调用之前该寄存器的值。**

当发生函数调用时：

- **实参、返回地址、ebp 寄存器首先入栈；**
- **然后再分配一块内存供局部变量、返回值等使用，这块内存一般比较大，足以容纳所有数据，并且会有冗余；**
- **最后将其他寄存器的值压入栈中。**

需要注意的是，不同编译器在不同编译模式下所产生的函数栈并不完全相同，例如在VS2010下选择Release模式，编译器会进行大量优化，函数栈的样貌荡然无存。

## 关于数据的定位

由于 esp 的值会随着数据的入栈而不断变化，要想根据 esp 找到参数、局部变量等数据是比较困难的，所以在实现上是根据 ebp 来定位栈内数据的。ebp 的值是固定的，数据相对 ebp 的偏移也是固定的，ebp 的值加上偏移量就是数据的地址。

例如一个函数的定义如下：

```cpp
void func(int a, int b)



{



    float f = 28.5;



    int n = 100;



    //TODO:



}
```

调用形式为：

```
func(15, 92);
```

那么函数的活动记录如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/9d161ad45896c270f123d6a117ceff06.png)


这里我们假设两个局部变量挨着，并且第一个变量和 old ebp 也挨着（实际上它们之间有4个字节的空白），如此，第一个参数的地址是 ebp+12，第二个参数的地址是 ebp+8，第一个局部变量的地址是 ebp-4，第二个局部变量的地址是 ebp-8。

## 调用惯例

我们知道，一个C程序由若干个函数组成，C程序的执行实际上就是函数之间的相互调用。请看下面的代码：

```cpp
#include <stdio.h>
 
void funcA(int m, int n)
{
    printf("funcA被调用\n");
}
 
void funcB(float a, float b)
{
    funcA(100, 200);
    printf("funcB被调用\n");
}
 
int main()
{
    funcB(19.9, 28.5);
    printf("main被调用\n");
    return 0;
}
```

main() 调用了 funcB()，funcB() 又调用了 funcA()。对于main() 调用 funcB()，我们称 main() 是调用方，funcB() 是被调用方；同理，对于 funcB() 调用 funcA()，funcB() 是调用方，funcA() 是被调用方。函数的参数（实参）由调用方压入栈中供被调用方使用，它们之间要有一致的约定。例如，参数是从左到右入栈还是从右到左入栈，如果双方理解不一致，被调用方使用参数时就会出错。以 funcB() 为例，假设 main() 函数先将 19.9 入栈，后将 28.5 入栈，但是 funcB() 在使用这些实参时却认为 28.5 先入栈，19.9 后入栈，那么就一定会产生混乱，误以为19.9 是传递给 b、28.5 是传递给 a 的。所以，函数调用方和被调用方必须遵守同样的约定，理解要一致，这称为**调用惯例（Calling Convention）**。

一个调用惯例一般规定以下两方面的内容：

**（1）函数参数的传递方式，是通过栈传递还是通过寄存器传递（这里我们只讲解通过栈传递的情况）。**

**（2）函数参数的传递顺序，是从左到右入栈还是从右到左入栈。**

**（3） 参数弹出方式。函数调用结束后需要将压入栈中的参数全部弹出，以使得栈在函数调用前后保持一致。这个弹出的工作可以由调用方来完成，也可以由被调用方来完成。**

**（4）函数名修饰方式。函数名在编译时会被修改，调用惯例可以决定如何修改函数名。**

在C语言中，存在多种调用惯例，可以在函数声明或函数定义时指定，例如：

```cpp
#include <stdio.h>
 
int __cdecl max(int m, int n);
 
int main()
{
    int a = max(10, 20);
    printf("a = %d\n", a);
    return 0;
}
 
int __cdecl max(int m, int n)
{
    int max = m>n ? m : n;
    return max;
}
```

函数调用惯例在函数声明和函数定义时都可以指定，语法格式为：

```
返回值类型 调用惯例 函数名(函数参数)
```

在函数声明处是为调用方指定调用惯例，而在函数定义处是为被调用方（也就是函数本身）指定调用惯例。__cdecl是C语言默认的调用惯例，在平时编程中，我们其实很少去指定调用惯例，这个时候就使用默认的 __cdecl。

**注意：__cdecl 并不是标准关键字，上面的写法在 VC/VS 下有效，但是在 GCC 下，要使用 __attribute__((cdecl))。**

除了 cdecl，还有其他调用惯例，请看下表：

| 调用惯例 | 参数传递方式                                            | 参数出栈方式          | 名字修饰                                                     |
| :------- | :------------------------------------------------------ | :-------------------- | :----------------------------------------------------------- |
| cdecl    | 按照从右到左的顺序入栈                                  | 调用方                | 下划线+函数名， 如函数 max() 的修饰名为 _max                 |
| stdcall  | 按照从右到左的顺序入栈                                  | 函数本身 （被调用方） | 下划线+函数名+@+参数的字节数， 如函数 int max(int m, int n) 的修饰名为 _max_@8 |
| fastcall | 将部分参数放入寄存器， 剩下的参数按照从右到左的顺序入栈 | 函数本身 （被调用方） | @+函数名+@+参数的字节数                                      |
| pascal   | 按照从左到右的顺序入栈                                  | 函数本身 （被调用方） | 较为复杂，这里不再展开讨论                                   |

## 深入剖析进出栈过程

我们以 VS2010 Debug 模式为例来深入分析一下。

请看下面的伪代码：

```cpp
void func(int a, int b）
{
    int p =12, q = 345;
}
int main()
{
    func(90, 26);
    return 0;
}
```

函数使用默认的调用惯例 cdecl，即参数从右到左入栈，由调用方负责将参数出栈。函数的进栈出栈过程如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/d75c4b2b514a2c3613376f9fe81ce981.png)

### 函数进栈

步骤①到⑥是函数进栈过程：

**（1）main() 是主函数，也需要进栈，如步骤①所示。**

**（2）在步骤②中，执行语句func(90, 26);，先将实参 90、26 压入栈中，再将返回地址压入栈中，这些工作都由 main() 函数（调用方）完成。这个时候 ebp 的值并没有变，仅仅是改变 esp 的指向。**

**（3）到了步骤③，就开始执行 func() 的函数体了。首先将原来 ebp 寄存器的值压入栈中（也即图中的 old ebp），并将 esp 的值赋给 ebp，这样 ebp 就从 main() 函数的栈底指向了 func() 函数的栈底，完成了函数栈的切换。由于此时 esp 和ebp 的值相等，所以它们也就指向了同一个位置。**

**（4）为局部变量、返回值等预留足够的内存，如步骤④所示。由于栈内存在函数调用之前就已经分配好了，所以这里并不是真的分配内存，而是将 esp 的值减去一个整数，例如 esp - 0XC0，就是预留 0XC0 字节的内存。**

**（5）将 ebp、esi、edi 寄存器的值依次压入栈中。**

**（6）将局部变量的值放入预留好的内存中。注意，第一个变量和 old ebp 之间有4个字节的空白，变量之间也有若干字节的空白。**

为什么要留出这么多的空白，岂不是浪费内存吗？这是因为我们使用Debug模式生成程序，留出多余的内存，方便加入调试信息；以Release模式生成程序时，内存将会变得更加紧凑，空白也被消除。

至此，func() 函数的活动记录就构造完成了。可以发现，在函数的实际调用过程中，形参是不存在的，不会占用内存空间，内存中只有实参，而且是在执行函数体代码之前、由调用方压入栈中的。

### 未初始化的局部变量的值为什么是垃圾值？

为局部变量分配内存时，仅仅是将 esp 的值减去一个整数，预留出足够的空白内存，不同的编译器在不同的模式下会对这片空白内存进行不同的处理，可能会初始化为一个固定的值，也可能不进行初始化。

例如在VS2010 Debug模式下，会将预留出来的内存初始化为 0XCCCCCCCC，如果不对局部变量赋值，它们的内存就不会改变，输出时的结果就是 0XCCCCCCCC，请看下面的代码：

```cpp
#include <stdio.h>
#include <stdlib.h>
 
int main()
{
    int m, n;
    printf("%#X, %#X\n", m, n);
    system("pause");
    return 0;
}
```

运行结果：

```
0XCCCCCCCC, 0XCCCCCCCC
```

虽然编译器对空白内存进行了初始化，但这个值对我们来说一般没有意义，所以我们可以认为它是垃圾值、是随机的。

### 函数出栈

步骤⑦到⑨是函数 func() 出栈过程：

**（7）函数 func() 执行完成后开始出栈，首先将 edi、esi、ebx 寄存器的值出栈。**

**（8）将局部变量、返回值等数据出栈时，直接将 ebp 的值赋给 esp，这样 ebp 和 esp 就指向了同一个位置。**

**（9）接下来将 old ebp 出栈，并赋值给现在的 ebp，此时 ebp 就指向了 func() 调用之前的位置，即 main() 活动记录的 old ebp 位置，如步骤⑨所示。**

这一步很关键，保证了还原到函数调用之前的情况，这也是每次调用函数时都必须将 old ebp 压入栈中的原因。

最后根据返回地址找到下一条指令的位置，并将返回地址和实参都出栈，此时 esp 就指向了 main() 活动记录的栈顶， 这意味着 func() 完全出栈了，栈被还原到了 func() 被调用之前的情况。

**5.4、遗留的错误认知**

经过上面的分析可以发现，函数出栈只是在增加 esp 寄存器的值，使它指向上一个数据，并没有销毁之前的数据。前面我们讲局部变量在函数运行结束后立即被销毁其实是错误的，这只是为了让大家更容易理解，对局部变量的作用范围有一个清晰的认识。栈上的数据只有在后续函数继续入栈时才能被覆盖掉，这就意味着，只要时机合适，在函数外部依然能够取得局部变量的值。请看下面的代码：

```cpp
#include <stdio.h>
 
int *p;
 
void func(int m, int n)
{
    int a = 18, b = 100;
    p = &a;
}
 
int main()
{
    int n;
    func(10, 20);
    n = *p;
    printf("n = %d\n", n);
    return 0;
}
```

运行结果：

```
n = 18
```

在 func() 中，将局部变量 a 的地址赋给 p，在 main() 函数中调用 func()，函数刚刚调用结束，还没有其他函数入栈，局部变量 a 所在的内存没有被覆盖掉，所以通过语句n = *p;能够取得它的值。

# 栈溢出攻击

我们先来看下面的一个例子：

```cpp
#include <stdio.h>
 
int main()
{
    char str[10] = {0};
    gets(str);
    printf("str: %s\n", str);
    return 0;
}
```

在 main() 函数内部定义一个字符数组，并通过 gets() 为它赋值。

在VS2010 Debug模式下运行程序，当输入的字符不超过10个时，可以正确输出，但是当输入的字符过多时，就会出现运行时错误。例如输入"12345678901234567890"，就会出现下面的错误：

![img](https://img-blog.csdnimg.cn/img_convert/24a4d28ba08a637d414ffd354539c08b.png)


这是为什么呢？我们不妨先来看一下 main() 函数的栈：

![img](https://img-blog.csdnimg.cn/img_convert/0338d57f02dd2c3efe0ec39314976dea.png)

局部数组也是在栈上分配内存，当输入"12345678901234567890" 时，会发生数组溢出，占用“4字节空白内存”、“old ebp”和“返回地址”所在的内存，并将原有的数据覆盖掉，这样当 main() 函数执行完成后，会取得一个错误的返回地址，该地址上的指令是不确定的，或者根本就没有指令，所以程序在返回时出错。

C语言不会对数组溢出做检测，这是一个典型的由于数组溢出导致覆盖了函数返回地址的例子，我们将这样的错误称为“**栈溢出错误**”。

**注意：这里所说的“栈溢出”是指栈上的某个数据过大，覆盖了其他的数据**，和《[10-栈的概念以及栈溢出](https://blog.csdn.net/Neutionwei/article/details/109659572)》中提到的栈溢出不是一回事。

**局部数组在栈上分配内存，并且不对数组溢出做检测，这是导致栈溢出的根源。**除了上面讲到的 gets() 函数，strcpy()、scanf() 等能够向数组写入数据的函数都有导致栈溢出的风险。

下面是使用 strcpy() 函数导致栈溢出的例子：

```cpp
#include <stdio.h>
#include <string.h>
 
int main()
{
    char *str1 = "neutionwei";
    char str2[6] = {0};
    strcpy(str2, str1);
    printf("str: %s\n", str2);
    return 0;
}
```

将 str1 复制到 str2，显然超出了 str2 的接受范围，会发生溢出，覆盖返回地址，导致 main() 函数返回时出错。

栈溢出一般不会产生严重的后果，但是如果有用户精心构造栈溢出，让返回地址指向恶意代码，那就比较危险了，这就是常说的栈溢出攻击。

# 动态内存分配

## 动态内存分配

所谓**动态内存分配**(Dynamic Memory Allocation)就是指在程序执行的过程中动态地分配或者回收存储空间的分配内存的方法。

动态内存分配不像数组等静态内存分配方法那样需要预先分配存储空间，而是由系统根据程序的需要即时分配，且分配的大小就是程序要求的大小。

动态内存分配较静态内存分配有以下两个特点：

（1）不需要预先分配存储空间；

（2）分配的空间可以根据程序的需要扩大或缩小。

在C语言中，提供了malloc()和calloc()函数来动态地取得内存空间。

## malloc()和free()函数

malloc()和free()是最常用的动态内存分配函数。如果在执行时需要空间来存储数据，则适合使用malloc()函数，用完则用free()释放该内存空间。

malloc()的格式为：

```cpp
指针 = malloc(空间大小);
```

例如：pstr = malloc(100);

这个指令要求计算机分配100Bytes空间。malloc()函数会返回该空间的地址，且存入pstr内，于是pstr指向该空间。

malloc()定义于malloc.h头文件中。

free()函数归还于malloc()所申请的空间。其格式为：

```cpp
free(指针);
```

例如：free(pstr);

当malloc()要求空间时，万一计算机无法提供足够的空间，就返回NULL指针。所以，如果pstr等于NULL，就表示内存空间不足，无法满足malloc()的要求。编写程序时，应养成“检查malloc()返回指针值是否为NULL”的好习惯。

## calloc()和realloc()函数

calloc()函数的格式为：

```cpp
指针 = calloc(n,size);
```

- **n：共有n个数据；**
- **size：每项需要size个bytes的空间。**

realloc()函数能扩大或缩小已取得的内存空间。格式如下：

```cpp
指针 = realloc(原先的指针，现需空间的大小);
```

请注意，**计算机可能会另外找一块足够大的空间来取代原先分配的空间。因此，新返回的指针值可能与原先的指针值不同**。

# 内存池

相对于栈而言，堆这片内存面临着一个稍微复杂的行为模式：在任意时刻，程序可能发出请求，要么申请一段内存，要么释放一段已经申请过的内存，而且申请的大小从几个字节到几个GB都有可能，我们不能假设程序一次申请多少堆空间，因此，堆的管理显得较为复杂。

那么，使用 malloc() 在堆上分配内存到底是如何实现的呢？

一种做法是**把 malloc() 的内存管理交给系统内核去做**，既然内核管理着进程的地址空间，那么如果它提供一个系统调用，可以让 malloc() 使用这个系统调用去申请内存，不就可以了吗？当然这是一种理论上的做法，但实际上这样做的性能比较差，因为**每次程序申请或者释放堆空间都要进行系统调用**。我们知道系统调用的性能开销是比较大的，当程序对堆的操作比较频繁时，这样做的结果会严重影响程序的性能。

比较好的做法就是 **malloc() 向操作系统申请一块适当大小的堆空间，然后由 malloc() 自己管理这块空间**。

**malloc() 相当于向操作系统“批发”了一块较大的内存空间，然后“零售”给程序用。当全部“售完”或程序有大量的内存需求时，再根据实际需求向操作系统“进货”**。当然 malloc() 在向程序零售堆空间时，必须管理它批发来的堆空间，不能把同一块地址出售两次，导致地址的冲突。于是 malloc() 需要一个算法来管理堆空间，这个算法就是**堆的分配算法**。

## malloc()和free()的分配算法

在程序运行过程中，堆内存从低地址向高地址连续分配，随着内存的释放，会出现不连续的空闲区域，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/b9c9edd2aa435f1775a8536c6445b319.png)

**带阴影的方框是已被分配的内存，白色方框是空闲内存或已被释放的内存**。程序需要内存时，malloc() 首先遍历空闲区域，看是否有大小合适的内存块，如果有，就分配，如果没有，就向操作系统申请（发生系统调用）。为了保证分配**给程序的内存的连续性**，malloc() 只会在一个空闲区域中分配，而不能将多个空闲区域联合起来。

内存块（包括已分配和空闲的）的结构类似于链表，它们之间通过指针连接在一起。在实际应用中，一个内存块的结构如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/961a690e1a250b916b03b758b2dd715e.png)

next 是指针，指向下一个内存块，used 用来表示当前内存块是否已被使用。这样，整个堆区就会形成如下图所示的链表（类似链表的内存管理方式）：

![img](https://img-blog.csdnimg.cn/img_convert/158961adfd7b14c8b5ecf3eb8d8670bb.png)

现在假设需要为程序分配100个字节的内存，当搜索到图中第一个空闲区域（大小为200个字节）时，发现满足条件，那么就在这里分配。这时候 malloc() 会把第一个空闲区域拆分成两部分，一部分交给程序使用，剩下的部分任然空闲，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/810728d57a83c6f0a68256834ef4dbc4.png)

仍然以图3为例，当程序释放掉第三个内存块时，就会形成新的空闲区域，free() 会将第二、三、四个连续的空闲区域合并为一个，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/c5c6293f34b8b1e978dad7bc100be0f9.png)

可以看到，malloc() 和 free() 所做的工作主要是对已有内存块的分拆和合并，并没有频繁地向操作系统申请内存，这大大提高了内存分配的效率。

另外，由于单向链表只能向一个方向搜索，在合并或拆分内存块时不方便，所以大部分 malloc() 实现都会在内存块中增加一个 pre 指针指向上一个内存块，构成**双向链表**，如下图所示：

![img](https://img-blog.csdnimg.cn/img_convert/ab615e6c9a987d71df413256b9d27345.png)

链表是一种经典的堆内存管理方式，经常被用在教学中，很多C语言教程都会提到“**栈内存的分配类似于数据结构中的栈，而堆内存的分配却类似于数据结构中的链表**”就是源于此。

链表式内存管理虽然思路简单，容易理解，但存在很多问题，例如：

- **一旦链表中的 pre 或 next 指针被破坏，整个堆就无法工作，而这些数据恰恰很容易被越界读写所接触到。**
- **小的空闲区域往往不容易再次分配，形成很多内存碎片。**
- **经常分配和释放内存会造成链表过长，增加遍历的时间。**

针对链表的缺点，后来人们提出了位图和对象池的管理方式，而现在的 malloc() 往往采用多种方式复合而成，不同大小的内存块往往采用不同的措施，以保证内存分配的安全和效率。

## 内存池

不管具体的分配算法是怎样的，为了减少系统调用，减少物理内存碎片，**malloc() 的整体思想是先向操作系统申请一块大小适当的内存，然后自己管理，这就是内存池（Memory Pool）**。

内存池的研究重点不是向操作系统申请内存，而是**对已申请到的内存的管理**，这涉及到非常复杂的算法，是一个永远也研究不完的课题，除了C标准库自带的 malloc()，还有一些第三方的实现，比如 Goolge 的 tcmalloc 和 jemalloc。

我们知道，C/C++是编译型语言，没有内存回收机制，程序员需要自己释放不需要的内存，这在给程序带来了很大灵活性的同时，也带来了不少风险，例如C/C++程序经常会发生内存泄露，程序刚开始运行时占用内存很少，**随着时间的推移，内存使用不断增加，导致整个计算机运行缓慢**。

内存泄露的问题往往难于调试和发现，或者只有在特定条件下才会复现，这给代码修改带来了不少障碍。为了提高程序的稳定性和健壮性，后来的 Java、Python、C#、JavaScript、PHP 等使用了虚拟机机制的非编译型语言都加入了垃圾内存自动回收机制，这样程序员就不需要管理内存了，系统会自动识别不再使用的内存并把它们释放掉，避免内存泄露。可以说，**这些高级语言在底层都实现了自己的内存池，也即有自己的内存管理机制**。

## 池化技术

在计算机中，有很多使用“池”这种技术的地方，除了内存池，还有连接池、线程池、对象池等。以服务器上的线程池为例，它的主要思想是：**先启动若干数量的线程，让它们处于睡眠状态，当接收到客户端的请求时，唤醒池中某个睡眠的线程，让它来处理客户端的请求，当处理完这个请求，线程又进入睡眠状态**。

**所谓“池化技术”，就是程序先向系统申请过量的资源，然后自己管理，以备不时之需。**之所以要申请过量的资源，是因为每次申请该资源都有较大的开销，不如提前申请好了，这样使用时就会变得非常快捷，大大提高程序运行效率。

# 野指针

## 野指针

野指针通常是因为指针变量中保存的值不是一个合法的内存地址而造成的。

合法的内存地址：

1. **在堆空间动态申请的；**
2. **局部变量所在的栈。**

野指针不是NULL指针，**是指向不可用内存的指针，也可能是一个动态的内存地址，但是这个内存别人正在使用，这也是不合法的地址**。

NULL指针不容易用错，因为 if 语句很好判断一个指针是不是NULL。C语言中没有任何手段可以判断一个指针是否为野指针！

## 野指针的由来

**（1）局部指针变量没有被初始化；**

```cpp
#include <stdio.h>
#include <string.h>
 
struct Student
{
    char* name;
    int number;
};
 
int main()
{
    struct Student s;
    strcpy(s.name, "Delphi Tang"); // OOPS!
    s.number = 99;
    return 0;
}
```

**局部变量没有被初始化，指针name指向的内存空间地址是随机的，当然不能向随机地址空间写数据。**

**（2）使用已经释放过后的指针；**

```cpp
#include <stdio.h>
#include <malloc.h>
#include <string.h>
 
void func(char* p)
{
    printf("%s\n", p);
    free(p);
}
 
int main()
{
    char* s = (char*)malloc(5);
    strcpy(s, "Delphi Tang");//数组越界
    func(s);
    printf("%s\n", s); // OOPS!使用已经释放的指针s
    return 0;
}
```

**释放一片指针后，意味着把这片内存归还到空闲链表，归还意味着其它程序可以使用这片空间，如果写了其它程序使用的空间，可能导致其它程序莫名其妙的被关闭。**

**（3）指针所指向的变量在指针之前被销毁。**

```cpp
#include <stdio.h>
 
char* func()
{
    char p[] = "Delphi Tang";
    return p;
}
 
int main()
{
    char* s = func();
    printf("%s\n", s); // OOPS!
    return 0;
}
```

函数调用的时候，在栈区存放局部变量，p是局部数组，放在活动记录里面，func返回之后，栈顶指针退出，活动记录占用内存已经被释放掉，**s指向一个被释放掉了栈空间**，如果栈空间值被修改了，就不会打印出预期结果，s是个野指针。

## 非法内存操作分析

**（1）结构体成员指针未初始化；**

**（2）没有为结构体指针分配足够的内存；**

```cpp
#include <stdio.h>
#include <malloc.h>
 
struct Demo
{
    int* p;
};
 
int main()
{
    struct Demo d1;
    struct Demo d2;
    int i = 0;
 
    for(i=0; i<10; i++)
    {
        d1.p[i] = 0; // OOPS!结构体指针未初始化
    }   
    d2.p = (int*)calloc(5, sizeof(int));   
    for(i=0; i<10; i++)
    {
        d2.p[i] = i; // OOPS!数组越界
    }
    free(d2.p);
    return 0;
}
```

**（3）内存初始化分析**

内存分配成功，但未初始化：

```cpp
int main(void)
{
    char *s = (char*)malloc(10);
    printf(s);//没有在内存中填充数据，就相当然作为字符串来使用，是不是字符串还不一定
    free(s);
    return 0;
}
```

以上程序只需改写一个字母就会绝对正确。

**（4）内存越界分析**

**数组越界：**

```cpp
#include <stdio.h>
 
void f(int a[10])
{
    int i = 0;    
    for(i=0; i<10; i++)
    {
        a[i] = i; // OOPS!
        printf("%d\n", a[i]);
    }
}
 
int main()
{
    int a[5];
    f(a);
    return 0;
}
```

**（5）内存泄露**

```cpp
#include <stdio.h>
#include <malloc.h>
 
void f(unsigned int size)
{
    int* p = (int*)malloc(size*sizeof(int));
    int i = 0;
 
    if( size % 2 != 0 )
    {
        return; // OOPS!出口1，还没有释放内存就结束
    }
    for(i=0; i<size; i++)
    {
        p[i] = i;
        printf("%d\n", p[i]);
    }
    free(p);//出口2
}
//f函数有一个入口，两个出口，最好“单入口，单出口”
 
int main()
{
    f(9);
    f(10);
    return 0;
}
```

修改后“单入口，单出口”

```cpp
#include <stdio.h>
#include <malloc.h>
 
void f(unsigned int size)
{
    int* p = (int*)malloc(size*sizeof(int));
    int i = 0;
 
    if( size % 2 == 0 )
    {
        for(i=0; i<size; i++)
     	{
        	p[i] = i;
            printf("%d\n", p[i]);
   		}
    }
    free(p);
}
 
int main()
{
    f(9);
    f(10);
    return 0;
}
```

**（6）多次释放指针**

**会导致异常退出**

```cpp
#include <stdio.h>
#include <malloc.h>
 
void f(int* p, int size)
{
    int i = 0;
    for(i=0; i<size; i++)
    {
        p[i] = i;
        printf("%d\n", p[i]);
    }
    free(p);//释放
}
 
int main()
{
    int* p = (int*)malloc(5 * sizeof(int));
    f(p, 5);
    free(p); // OOPS!二次释放
    return 0;
}
```

**解决方法：谁申请谁释放，在main中申请就在main中释放。**

以上程序也可以采取这样的解决方法,在f函数中增加第三个参数，然后在main中决定是否释放

```cpp
#include <stdio.h>
#include <malloc.h>
 
void f(int* p, int size，int toFree)
{
    int i = 0;   
    for(i=0; i<size; i++)
    {
        p[i] = i;
        printf("%d\n", p[i]);
    }
    if(toFree)
    {
        free(p);//释放
    }
}
 
int main()
{
    int* p = (int*)malloc(5 * sizeof(int));
    f(p, 5, 0);
    free(p); // OOPS!二次释放
    return 0;
}
```

**（7）使用已释放的指针**

```cpp
#include <stdio.h>
#include <malloc.h>
 
void f(int* p, int size)
{
    int i = 0;
    for(i=0; i<size; i++)
    {
        printf("%d\n", p[i]);
    }
    free(p);
}
 
int main()
{
    int* p = (int*)malloc(5 * sizeof(int));
    int i = 0;
 
    f(p, 5);//在函数f中已经释放p指向的内存
    for(i=0; i<5; i++)//而又在此处操作p所指向的内存，p是野指针。
    {
        p[i] = i; // OOPS!
    }
    return 0;
}
```

## C语言中的交通规则

**（1）用malloc申请了内存之后，应该立即检查指针值是否为NULL，防止使用值为NULL的指针；**

这样可以杜绝操作0内存地址的内容，0内存地址是非常特殊的地址，是操作系统所使用的。

```cpp
int *p = (int*)malloc(5 * sizeof(int));
if( p != NULL )
{
    //do something here!
}
free(p);
```

**（2）牢记数组的长度，防止数组越界操作，考虑使用柔性数组；**

```cpp
typedef struct _soft_array
{
    int len;
    int array[];
}SoftArray;
 
 
int i = 0;
SoftArray *sa = (SoftArray*)malloc(sizeof(SoftArray) + sizeof(int)*10);
sa->len = 10;
 
for(i=0; i<sa->len; i++)
{
    sa->array[i] = i+1;
}
```

**（3）动态申请的操作必须和释放操作匹配，防止内存泄露和多次释放；**

```cpp
void f()
{
    int *p = (int*)malloc(5);
    free(p);
}
 
int main()
{
    int *p = (int*)malloc(10);
    f();
    free(p);;
    return 0;
}
```

**（4）free指针之后必须立即赋值为NULL。**

```cpp
int *p = (int*)malloc(10);
free(p);
p = NULL;
 
//...
//......
//.........
 
if(p != NULL)
{
    int i = 0;
    for(i=0; i<5; i++)
    {
        p[i] = i;
    }
}
```

 # 变量存储类别&生存期

**从变量值存在的作用时间（即生存周期）角度来分，可以分为静态存储方式和动态存储方式。**

- **静态存储方式：是指在程序运行期间分配固定的存储空间的方式。**
- **动态存储方式：是在程序运行期间根据需要进行动态的分配存储空间的方式。**

> 从变量的作用域（即从空间）角度来分，可以分为全局变量和局部变量。

用户存储空间可以分为三个部分：

1. **程序区；**
2. **静态存储区；**
3. **动态存储区。**

全局变量全部存放在静态存储区，在程序开始执行时给全局变量分配存储区，程序行完毕就释放。**在程序执行过程中它们占据固定的存储单元，而不动态地进行分配和释放**。

动态存储区存放以下数据：

1. **函数形式参数；**
2. **自动变量（未加static声明的局部变量）；**
3. **函数调用时的现场保护和返回地址。**

在C语言中，每个变量和函数有两个属性：**数据类型和数据的存储类别**。

## auto变量

**函数中的局部变量**，如不专门声明为static存储类别，都是动态地分配存储空间的，数据存储在动态存储区中。

函数中的形参和在函数中定义的变量（包括在复合语句中定义的变量），都属此类，在调用该函数时系统会给它们分配存储空间，在函数调用结束时就自动释放这些存储空间。这类局部变量称为自动变量。自动变量用关键字auto作存储类别的声明

## 用static声明局部变量

有时希望函数中的局部变量的值在函数调用结束后不消失而保留原值，这时就应该指定局部变量为“静态局部变量”，用关键字static进行声明。

对静态局部变量的说明：

- **静态局部变量属于静态存储类别，在静态存储区内分配存储单元。在程序整个运行期间都不释放。而自动变量（即动态局部变量）属于动态存储类别，占动态存储空间，函数调用结束后即释放。**
- **静态局部变量在编译时赋初值，即只赋初值一次；而对自动变量赋初值是在函数调用时进行，每调用一次函数重新给一次初值，相当于执行一次赋值语句。**
- **如果在定义局部变量时不赋初值的话，则对静态局部变量来说，编译时自动赋初值0（对数值型变量）或空字符（对字符变量）。而对自动变量来说，如果不赋初值则它的值是一个不确定的值。**

## register变量

为了提高效率，**C语言允许将局部变量得值放在CPU中的寄存器中，这种变量叫“寄存器变量”**，用关键字register作声明。

对寄存器变量的几点说明：

- **只有局部自动变量和形式参数可以作为寄存器变量；**
- **一个计算机系统中的寄存器数目有限，不能定义任意多个寄存器变量；**
- **局部静态变量不能定义为寄存器变量。**

## 用extern声明外部变量

外部变量（即全局变量）是在函数的外部定义的，它的作用域为从变量定义处开始，到本程序文件的末尾。如果外部变量不在文件的开头定义，其有效的作用范围只限于定义处到文件终了。如果在定义点之前的函数想引用该外部变量，则应该在引用之前用关键字extern对该变量作“外部变量声明”。表示该变量是一个已经定义的外部变量。有了此声明，就可以从“声明”处起，合法地使用该外部变量。

### extern的用法

在C语言中，修饰符extern用在变量或者函数的声明前，用来说明“此变量/函数是在别处定义的，要在此处引用”

1. **extern修饰变量的声明**
2. **extern修饰函数声明**
3. **extern修饰符可用于指示C或者C＋＋函数的调用规范**

**C＋＋中调用C库函数，就需要在C＋＋程序中用extern “C”声明要引用的函数。**这是给链接器用的，告诉链接器在链接的时候用C函数规范来链接。主要原因是C＋＋和C程序编译完成后在目标代码中命名规则不同

